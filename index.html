<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="description"
    content="Implicit Neural Fusion for LiDAR and Camera.">
<meta name="keywords" content="INF">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>INF</title>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
    rel="stylesheet">
    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link href="static/css/style.css" rel="stylesheet" type="text/css">
</head>

<body>
<section class="hero">
        <div class="hero-body">
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column has-text-centered">
                <h1 class="title is-1 publication-title">INF: Implicit Neural Fusion for LiDAR and Camera</h1>
                <div class="is-size-5 publication-authors">
                  <span class="author-block">
                    Shuyi Zhou<sup>1, 2</sup>,</span>
                  <span class="author-block">
                    Shuxiang Xie<sup>1, 2</sup>,</span>
                  <span class="author-block">
                    Ryoichi Ishikawa<sup>1</sup>,
                  </span>
                  <span class="author-block">
                    Ken Sakurada<sup>2</sup>,
                  </span>
                  <span class="author-block">
                    Masaki Onishi<sup>2</sup>,
                  </span>
                  <span class="author-block">
                    Takeshi Oishi<sup>1</sup>,
                  </span>
                </div>
      
                <div class="is-size-6 publication-authors mt-2">
                  <span class="author-block"><sup>1</sup>The University of Tokyo,</span>
                  <span class="author-block"><sup>2</sup>National Institute of Advanced Industrial Science and Technology</span>
                </div>
      
                <div class="column has-text-centered">
                  <div class="publication-links">
                    <!-- Paper Link. -->
                    <span class="link-block">
                      <a href="http://arxiv.org/abs/2308.14414"
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                    <!-- Code Link. -->
                    <span class="link-block">
                      <a href="https://github.com/ShuyiZhou495/INF"
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                      </a>
                    </span>
                    <!-- Data Link. -->
                    <span class="link-block">
                      <a href="https://github.com/ShuyiZhou495/INF#data"
                         class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="far fa-images"></i>
                        </span>
                        <span>Data</span>
                      </a>
                    </span>
                  </div>
      
                </div>
              </div>
            </div>
          </div>
        </div>
</section>

<div class="centered-container">

    <section class="section p0">
        <div id="imageCarousel" class="carousel slide" data-bs-ride="carousel">
            <div class="carousel-indicators">
                <button type="button" data-bs-target="#imageCarousel" data-bs-slide-to="0" class="active" aria-current="true" aria-label="Slide 1"></button>
                <button type="button" data-bs-target="#imageCarousel" data-bs-slide-to="1" aria-label="Slide 2"></button>
                <button type="button" data-bs-target="#imageCarousel" data-bs-slide-to="2" aria-label="Slide 3"></button>
              </div>
            <div class="carousel-inner">
                <div class="carousel-item active">
                    <div class="image-pair">
                        <span class="image-text">Rendered Depth</span>
                        <img class="img-fluid" src="static/images/depth1.jpg" alt="First Image Left">
                        <span class="image-text-right">Rendered Color</span>
                        <img class="img-fluid right-image" src="static/images/color1.jpg" alt="Second Image Right">
                    </div>
                    <div class="vertical-line"></div>
                </div>
                <div class="carousel-item">
                    <div class="image-pair">
                        <span class="image-text">Rendered Depth</span>
                        <img class="img-fluid" src="static/images/depth2.jpg" alt="First Image Left">
                        <span class="image-text-right">Rendered Color</span>
                        <img class="img-fluid right-image" src="static/images/color2.jpg" alt="Second Image Right">
                    </div>
                    <div class="vertical-line"></div>
                </div>
                <div class="carousel-item">
                    <div class="image-pair">
                        <span class="image-text">Rendered Depth</span>
                        <img class="img-fluid" src="static/images/depth3.jpg" alt="First Image Left">
                        <span class="image-text-right">Rendered Color</span>
                        <img class="img-fluid right-image" src="static/images/color3.jpg" alt="Second Image Right">
                    </div>
                    <div class="vertical-line"></div>
                </div>
            </div>
        </div>
    </section>

    <section class="section ">
        <div class="columns is-centered has-text-centered">            
            <h2 class="title is-3">
                Abstract
            </h2>
        </div>
        <p>Sensor fusion has become a popular topic in robotics. However, conventional fusion methods encounter many difficulties, such as data representation differences, sensor variations, and extrinsic calibration. For example, the calibration methods used for LiDAR-camera fusion often require manual operation and auxiliary calibration targets. Implicit neural representations (INRs) have been developed for 3D scenes, and the volume density distribution involved in an INR unifies the scene information obtained by different types of sensors. Therefore, we propose implicit neural fusion (INF) for LiDAR and camera. INF first trains a neural density field of the target scene using LiDAR frames. Then, a separate neural color field is trained using camera images and the trained neural density field. Along with the training process, INF both estimates LiDAR poses and optimizes extrinsic parameters. Our experiments demonstrate the high accuracy and stable performance of the proposed method. 
        </p>
    </section>
    
    <section class="section ">   
        <div class="columns is-centered has-text-centered">
                    <h2 class="title is-3">Method Overview</h2>
        </div>         

        <img src="static/images/overview.png" alt="Method Overview Diagram" class="img-fluid mb-4">
        <p class="mb-3">
            Processes shown by dashed lines indicate back-propagation, update and optimization.</p>
        <div class="columns is-centered">
        <div class="column">
            <div class="content">
                <h2 class="title is-3">Neural Density Field</h2>
                <p>
                We use LiDAR measurement data to train a neural density field that can represent the space geometry. Neural density field outputs the densities of sampled points, which can be integrated using volume rendering to calculate depth values of LiDAR rays. Notice that LiDAR poses can also be estimated in a sequential process using the neural density field. 
                </p>
            </div>
            </div>
            <div class="column">
            <h2 class="title is-3">Neural Color Field</h2>
            <div class="columns is-centered">
                <div class="column content">
                <p>
                    We also use camera data and trained density field to generate and refine a neural color field for color representation. nstead of directly defining camera poses, we derive the camera poses from LiDAR poses and LiDAR-camera extrinsic parameters.
                    In this way, the extrinsic parameters can be optimized, which is the key part of sensor fusion. 
                </p>
                </div>
    
            </div>
            </div>
        </div>
    </section>
    <section class="section ">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                  <h2 class="title is-3">Video</h2>
                  <div class="publication-video">
                    <iframe src="https://www.youtube.com/embed/I1MJ_tUdNB4"
                            frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  </div>
                </div>
              </div>
        </div>
    </section>
    <section class="section " id="BibTeX">
        <div class="container is-centered content">
          <h2 class="title">BibTeX</h2>
          <pre><code>@inproceedings{zhou2023inf,
    author    = {Shuyi, Zhou and Shuxiang, Xie and Ryoichi, Ishikawa and Ken, Sakurada and Masaki, Onishi and Takeshi, Oishi},
    title     = {INF: Implicit Neural Fusion for LiDAR and Camera},
    journal   = {IROS},
    year      = {2023}
    }
</code></pre>
</div>
</section>
</div>
<footer class="footer">
    <div class="container">
        <div class="content has-text-centered">
            <a class="icon-link" href="http://arxiv.org/abs/2308.14414">
              <i class="fas fa-file-pdf"></i>
            </a>
            <a class="icon-link" href="https://github.com/ShuyiZhou495/INF" class="external-link">
              <i class="fab fa-github"></i>
            </a>
          </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
                This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
                This webpage is built with the template from <a rel="license"
                href="https://github.com/nerfies/nerfies.github.io"> NeRFies </a>. We sincerely thank <a rel="license"
                href="https://keunhong.com/"> Keunhong Park </a> for developing and open-sourcing this template.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
<script src="static/js/script.js"></script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script defer src="./static/js/fontawesome.all.min.js"></script>
<script src="./static/js/bulma-carousel.min.js"></script>
<script src="./static/js/bulma-slider.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>